{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import base\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for data visualisation\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNo</th>\n",
       "      <th>Division</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Channel_of_Recruitment</th>\n",
       "      <th>Trainings_Attended</th>\n",
       "      <th>Year_of_birth</th>\n",
       "      <th>Last_performance_score</th>\n",
       "      <th>Year_of_recruitment</th>\n",
       "      <th>Targets_met</th>\n",
       "      <th>Previous_Award</th>\n",
       "      <th>Training_score_average</th>\n",
       "      <th>State_Of_Origin</th>\n",
       "      <th>Foreign_schooled</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Past_Disciplinary_Action</th>\n",
       "      <th>Previous_IntraDepartmental_Movement</th>\n",
       "      <th>No_of_previous_employers</th>\n",
       "      <th>Promoted_or_Not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YAK/S/00001</td>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>MSc, MBA and PhD</td>\n",
       "      <td>Female</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>1986</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>ANAMBRA</td>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAK/S/00002</td>\n",
       "      <td>Customer Support and Field Operations</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Agency and others</td>\n",
       "      <td>2</td>\n",
       "      <td>1991</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>ANAMBRA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAK/S/00003</td>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>KATSINA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAK/S/00004</td>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Agency and others</td>\n",
       "      <td>3</td>\n",
       "      <td>1982</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>NIGER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Single</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YAK/S/00006</td>\n",
       "      <td>Information and Strategy</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>AKWA IBOM</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EmployeeNo                               Division        Qualification  \\\n",
       "0  YAK/S/00001         Commercial Sales and Marketing     MSc, MBA and PhD   \n",
       "1  YAK/S/00002  Customer Support and Field Operations  First Degree or HND   \n",
       "2  YAK/S/00003         Commercial Sales and Marketing  First Degree or HND   \n",
       "3  YAK/S/00004         Commercial Sales and Marketing  First Degree or HND   \n",
       "4  YAK/S/00006               Information and Strategy  First Degree or HND   \n",
       "\n",
       "   Gender   Channel_of_Recruitment  Trainings_Attended  Year_of_birth  \\\n",
       "0  Female  Direct Internal process                   2           1986   \n",
       "1    Male        Agency and others                   2           1991   \n",
       "2    Male  Direct Internal process                   2           1987   \n",
       "3    Male        Agency and others                   3           1982   \n",
       "4    Male  Direct Internal process                   3           1990   \n",
       "\n",
       "   Last_performance_score  Year_of_recruitment  Targets_met  Previous_Award  \\\n",
       "0                    12.5                 2011            1               0   \n",
       "1                    12.5                 2015            0               0   \n",
       "2                     7.5                 2012            0               0   \n",
       "3                     2.5                 2009            0               0   \n",
       "4                     7.5                 2012            0               0   \n",
       "\n",
       "   Training_score_average State_Of_Origin Foreign_schooled Marital_Status  \\\n",
       "0                      41         ANAMBRA               No        Married   \n",
       "1                      52         ANAMBRA              Yes        Married   \n",
       "2                      42         KATSINA              Yes        Married   \n",
       "3                      42           NIGER              Yes         Single   \n",
       "4                      77       AKWA IBOM              Yes        Married   \n",
       "\n",
       "  Past_Disciplinary_Action Previous_IntraDepartmental_Movement  \\\n",
       "0                       No                                  No   \n",
       "1                       No                                  No   \n",
       "2                       No                                  No   \n",
       "3                       No                                  No   \n",
       "4                       No                                  No   \n",
       "\n",
       "  No_of_previous_employers  Promoted_or_Not  \n",
       "0                        0                0  \n",
       "1                        0                0  \n",
       "2                        0                0  \n",
       "3                        1                0  \n",
       "4                        1                0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "train_data = pd.read_csv('train-dsn.csv')\n",
    "test_data = pd.read_csv('test-dsn.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "n_test = test_data.shape[0]\n",
    "\n",
    "all_data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee No Train and test sets are distinct.\n"
     ]
    }
   ],
   "source": [
    "print('Employee No Train and test sets are distinct.') if len(np.intersect1d(train_data.EmployeeNo.values, test_data.EmployeeNo.values))== 0 else print('oops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the missing value with First Degree or HND\n",
    "all_data.Qualification.fillna('First Degree or HND', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking percentage of promoted clients\n",
    "promoted= train[train.Promoted_or_Not==1]\n",
    "not_p = train[train.Promoted_or_Not==0]\n",
    "percent_fraud = len(promoted)/(len(train.Promoted_or_Not))\n",
    "percent_fraud\n",
    "train.Promoted_or_Not.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[row slicing, column slicing]\n",
    "train.iloc[:, 18:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Channel_of_Recruitment</th>\n",
       "      <th>Trainings_Attended</th>\n",
       "      <th>Year_of_birth</th>\n",
       "      <th>Last_performance_score</th>\n",
       "      <th>Year_of_recruitment</th>\n",
       "      <th>Targets_met</th>\n",
       "      <th>Previous_Award</th>\n",
       "      <th>Training_score_average</th>\n",
       "      <th>Foreign_schooled</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Past_Disciplinary_Action</th>\n",
       "      <th>Previous_IntraDepartmental_Movement</th>\n",
       "      <th>No_of_previous_employers</th>\n",
       "      <th>Promoted_or_Not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>MSc, MBA and PhD</td>\n",
       "      <td>Female</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>1986</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Support and Field Operations</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Agency and others</td>\n",
       "      <td>2</td>\n",
       "      <td>1991</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Division        Qualification  Gender  \\\n",
       "0         Commercial Sales and Marketing     MSc, MBA and PhD  Female   \n",
       "1  Customer Support and Field Operations  First Degree or HND    Male   \n",
       "2         Commercial Sales and Marketing  First Degree or HND    Male   \n",
       "\n",
       "    Channel_of_Recruitment  Trainings_Attended  Year_of_birth  \\\n",
       "0  Direct Internal process                   2           1986   \n",
       "1        Agency and others                   2           1991   \n",
       "2  Direct Internal process                   2           1987   \n",
       "\n",
       "   Last_performance_score  Year_of_recruitment  Targets_met  Previous_Award  \\\n",
       "0                    12.5                 2011            1               0   \n",
       "1                    12.5                 2015            0               0   \n",
       "2                     7.5                 2012            0               0   \n",
       "\n",
       "   Training_score_average Foreign_schooled Marital_Status  \\\n",
       "0                      41               No        Married   \n",
       "1                      52              Yes        Married   \n",
       "2                      42              Yes        Married   \n",
       "\n",
       "  Past_Disciplinary_Action Previous_IntraDepartmental_Movement  \\\n",
       "0                       No                                  No   \n",
       "1                       No                                  No   \n",
       "2                       No                                  No   \n",
       "\n",
       "  No_of_previous_employers  Promoted_or_Not  \n",
       "0                        0              0.0  \n",
       "1                        0              0.0  \n",
       "2                        0              0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing irrelevant features\n",
    "feature = ['State_Of_Origin', 'EmployeeNo']\n",
    "data = all_data.drop(feature, axis=1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print out the missing values counts and percentage\n",
    "def display_missing(data=None, plot= None):\n",
    "    '''\n",
    "    Display missing values as a pandas dataframe.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: DataFrame or named Series\n",
    "    '''\n",
    "\n",
    "    if data is None:\n",
    "        raise ValueError(\"data: Expecting a DataFrame or Series, got 'None'\")\n",
    "\n",
    "    df = data.isna().sum()\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['features', 'missing_counts']\n",
    "\n",
    "    missing_percent = round((df['missing_counts'] / data.shape[0]) * 100, 2)\n",
    "    df['missing_percent'] = missing_percent\n",
    "\n",
    "    if plot:\n",
    "        plot_missing(data)\n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_missing(data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoted= data[data.Promoted_or_Not==1]\n",
    "promoted\n",
    "#promoted[promoted['Training_score_average'] >= 60]\n",
    "#promoted['Is_Married'] = 0\n",
    "#promoted[(promoted['recruitment_age'] <= 5) & (promoted['Previous_Award'] == 1)]\n",
    "#promoted[(promoted['Training_score_average'] >= 60) & (promoted['Targets_met'] == 1)]\n",
    "#promoted.Last_performance_score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENGINEER SOME MORE FEATURES WITH THE PREDICTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_map = {2: 1, 3: 2, 4: 3, 5: 3, 6: 3, 7: 4, 8: 4, \n",
    "                9:4 , 10: 4, 11: 4}\n",
    "data['Trainings_Attended'] = data['Trainings_Attended'].map(training_map)\n",
    "\n",
    "#data['training_total'] = data.apply(lambda x: x['Training_score_average'] * x['Trainings_Attended'], axis =1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Marketing_Targets'] = data.apply(lambda x: 1 if (x['Division'] == 'Commercial Sales and Marketing' and  x['Targets_met']) == 1 else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Qualification_Targets'] = data.apply(lambda x: 1 if (x['Qualification'] == 'First Degree or HND' and  x['Targets_met'] == 1 )else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Agency_Targets'] = data.apply(lambda x: 1 if (x['Channel_of_Recruitment'] == 'Agency and others' and  x['Targets_met'] == 1 )else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Performance_Targets'] = data.apply(lambda x: 1 if (x['Last_performance_score'] >= 5 and x['Targets_met'] == 1 )else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Training_Targets'] = data.apply(lambda x: 1 if (x['Training_score_average'] >= 75 )else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the first five rows in the data\n",
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Last_performance_score[data.Last_performance_score== 0.0]=1\n",
    "data.Last_performance_score[data.Last_performance_score== 2.5]=2\n",
    "data.Last_performance_score[data.Last_performance_score== 5.0]=3\n",
    "data.Last_performance_score[data.Last_performance_score== 7.5]=4\n",
    "data.Last_performance_score[data.Last_performance_score== 10.0]=5\n",
    "data.Last_performance_score[data.Last_performance_score== 12.5]=6\n",
    "data.Last_performance_score = data.Last_performance_score.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change No_of_previous_employers to categorical feature\n",
    "\n",
    "cat_map = {'0': 0, '1': 1, '2':2, '3': 3, '4':4, '5':5, 'More than 5': 6}\n",
    "\n",
    "data['No_of_previous_employers'] = data['No_of_previous_employers'].map(cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Skew for age:',data.Year_of_birth.skew())\n",
    "print('Skew for recruitment-age:',data.Year_of_recruitment.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = data['Year_of_birth'].apply(lambda x: 2019 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.age >50, 'age'] = 45\n",
    "\n",
    "max(data.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for features in categorical:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(data[features].values))\n",
    "    data[features] = lbl.transform(list(data[features].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['recruitment_age'] = data['Year_of_recruitment'].apply(lambda x: 2019 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Recruitment_Awards'] = data.apply(lambda x: 1 if (x['recruitment_age'] <= 4 and x['Training_score_average'] >= 70  )else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data.recruitment_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.recruitment_age >13, 'recruitment_age'] = 9\n",
    "max(data.recruitment_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Division','Last_performance_score','Trainings_Attended','Qualification','Channel_of_Recruitment']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def merge_groupby(data, cat_features=None, statistics=None, col_to_merge=None):\n",
    "    df = data.copy()\n",
    "    if statistics is None:     \n",
    "        statistics = ['mean']\n",
    "    for cat in cat_features:      \n",
    "        temp = df.groupby([cat]).agg(statistics)[col_to_merge]\n",
    "        print(temp)\n",
    "        #rename columns\n",
    "        temp = temp.rename(columns={'mean': cat + '_' + col_to_merge + '_mean'})\n",
    "        #merge the data sets\n",
    "        df = df.merge(temp, how='left', on=cat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "merge_groupby(data, cat_features=cat_features, col_to_merge='Training_score_average')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def calc_smooth_mean(df, by, on, m):\n",
    "    # Compute the global mean\n",
    "    mean = df[on].mean()\n",
    "\n",
    "    # Compute the number of values and the mean of each group\n",
    "    agg = df.groupby(by)[on].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "\n",
    "    # Compute the \"smoothed\" means\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "\n",
    "    # Replace each value by the according smoothed mean\n",
    "    return df[by].map(smooth)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data['x1'] = calc_smooth_mean(data,'Division','Promoted_or_Not', 15)\n",
    "data['x2'] = calc_smooth_mean(data,'Last_performance_score', 'Promoted_or_Not', 10)\n",
    "data['x3'] =calc_smooth_mean(data,'Qualification','Promoted_or_Not',5)\n",
    "data['x4'] =calc_smooth_mean(data,'Trainings_Attended','Promoted_or_Not', 10)\n",
    "data['x5'] =calc_smooth_mean(data,'Channel_of_Recruitment','Promoted_or_Not', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = data[:n_train]\n",
    "test = data[n_train:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['Promoted_or_Not' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data.Promoted_or_Not = t_data.Promoted_or_Not.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADVANCED FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTargetEncoderTrain(base.BaseEstimator, base.TransformerMixin):\n",
    "\n",
    "    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n",
    "\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)\n",
    "\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold, shuffle = False, random_state=2019)\n",
    "\n",
    "\n",
    "\n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan\n",
    "\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "#             print(tr_ind,val_ind)\n",
    "            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "\n",
    "        X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "\n",
    "        if self.verbosity:\n",
    "\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,\n",
    "                                                                                      self.targetName,\n",
    "                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n",
    "            if self.discardOriginal_col:\n",
    "                X = X.drop(self.targetName, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        \n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "\n",
    "        mean = self.train[[self.colNames,self.encodedName]].groupby(self.colNames).mean().reset_index() \n",
    "        \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "\n",
    "        \n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Last_performance_score_Kfold_Target_Enc and, Promoted_or_Not is 0.15547124007685606.\n"
     ]
    }
   ],
   "source": [
    "targetc = KFoldTargetEncoderTrain('Last_performance_score','Promoted_or_Not',n_fold=5)\n",
    "new_train = targetc.fit_transform(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Division_Kfold_Target_Enc and, Promoted_or_Not is 0.045805874763817485.\n"
     ]
    }
   ],
   "source": [
    "targetd = KFoldTargetEncoderTrain('Division','Promoted_or_Not',n_fold=5)\n",
    "new_train = targetd.fit_transform(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Qualification_Kfold_Target_Enc and, Promoted_or_Not is 0.0189980063125907.\n"
     ]
    }
   ],
   "source": [
    "targetc = KFoldTargetEncoderTrain('Qualification','Promoted_or_Not',n_fold=5)\n",
    "new_train = targetc.fit_transform(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Trainings_Attended_Kfold_Target_Enc and, Promoted_or_Not is 0.01911625308765594.\n"
     ]
    }
   ],
   "source": [
    "targetc = KFoldTargetEncoderTrain('Trainings_Attended','Promoted_or_Not',n_fold=5)\n",
    "new_train = targetc.fit_transform(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, Channel_of_Recruitment_Kfold_Target_Enc and, Promoted_or_Not is 0.014684656745026753.\n"
     ]
    }
   ],
   "source": [
    "targetc = KFoldTargetEncoderTrain('Channel_of_Recruitment','Promoted_or_Not',n_fold=5)\n",
    "new_train = targetc.fit_transform(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targetc = KFoldTargetEncoderTest(new_train,'Last_performance_score','Last_performance_score_Kfold_Target_Enc')\n",
    "test = test_targetc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targetc = KFoldTargetEncoderTest(new_train,'Division','Division_Kfold_Target_Enc')\n",
    "test = test_targetc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targetc = KFoldTargetEncoderTest(new_train,'Qualification','Qualification_Kfold_Target_Enc')\n",
    "test = test_targetc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targetc = KFoldTargetEncoderTest(new_train,'Trainings_Attended','Trainings_Attended_Kfold_Target_Enc')\n",
    "test = test_targetc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targetc = KFoldTargetEncoderTest(new_train,'Channel_of_Recruitment','Channel_of_Recruitment_Kfold_Target_Enc')\n",
    "test = test_targetc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = pd.qcut(data['age'], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = new_train.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'Trainings_Attended_Kfold_Target_Enc']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data['Promoted_or_Not']\n",
    "new_data = new_train.drop(['Promoted_or_Not','Year_of_birth','Year_of_recruitment','Marital_Status',\n",
    "                   'Foreign_schooled','Past_Disciplinary_Action','No_of_previous_employers',\n",
    "                'Trainings_Attended',\n",
    "                ], axis=1)\n",
    "new_test = test.drop(['Year_of_birth','Year_of_recruitment','Marital_Status',\n",
    "                   'Foreign_schooled','Past_Disciplinary_Action','No_of_previous_employers',\n",
    "                'Division','Last_performance_score','Trainings_Attended','Qualification','Channel_of_Recruitment'\n",
    "                ], axis=1)\n",
    "#'Previous_IntraDepartmental_Movement','Channel_of_Recruitment' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.get_dummies(new_data)\n",
    "test_dummies = pd.get_dummies(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38312, 30), (16496, 14))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape, test_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.apply(lambda x: 1/x).replace(np.inf, 0)\n",
    "new_data.Targets_met = new_data.Targets_met.astype(int)\n",
    "new_data.Previous_Award = new_data.Previous_Award.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generating all possible pair of interactions between 2 pair of columns.\n",
    "##Then removing those columns \n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def add_interactions(df):\n",
    "    combos = list(combinations(list(df.columns), 2))\n",
    "    colnames = list(df.columns)+['_'.join(x) for x in combos]\n",
    "    \n",
    "    #scaler = MinMaxScaler()\n",
    "    #scaler.fit(df)\n",
    "    #df = scaler.transform(df)\n",
    "    \n",
    "    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "    df = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = colnames\n",
    "    \n",
    "    noint_indices = [i for i,x in enumerate(list((df==0).all())) if x]\n",
    "    df= df.drop(df.columns[noint_indices], axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_interactions(train_data)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#\"Creates a polynomial regression model for the given degree\"\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "  \n",
    "  # transforms the existing features to higher degree features.\n",
    "xtrain_poly = poly_features.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape\n",
      "(30649, 30)\n",
      "xtest shape\n",
      "(7663, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(new_data, target, test_size=0.2, random_state=0, shuffle =True, stratify= target)\n",
    "print('xtrain shape')\n",
    "print(xtrain.shape)\n",
    "print('xtest shape')\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#\"Creates a polynomial regression model for the given degree\"\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "  \n",
    "  # transforms the existing features to higher degree features.\n",
    "xtrain_poly = poly_features.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_poly = poly_features.fit_transform(xtest),xtrain_poly .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 5))\n",
    "\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(train['Training_score_average'], ax=ax1)\n",
    "sns.kdeplot(data['age'], ax=ax1)\n",
    "#sns.kdeplot(train['Year_of_recruitment'], ax=ax1)\n",
    "sns.kdeplot(data['recruitment_age'], ax=ax1)\n",
    "\n",
    "num_attributes = ['Training_score_average','age','recruitment_age']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "feat = xtrain[num_attributes]\n",
    "scaler = MinMaxScaler().fit(feat.values)\n",
    "xtrain_s = scaler.transform(feat.values)\n",
    "scaled_df = pd.DataFrame(xtrain_s, columns=num_attributes)\n",
    "xtest_s = scaler.transform(xtest[num_attributes].values)\n",
    "\n",
    "# sns.kdeplot(df['x3'], ax=ax1)\n",
    "ax2.set_title('After Standard Scaler')\n",
    "sns.kdeplot(scaled_df['Training_score_average'], ax=ax2)\n",
    "sns.kdeplot(scaled_df['age'], ax=ax2)\n",
    "sns.kdeplot(scaled_df['recruitment_age'], ax=ax2)\n",
    "# sns.kdeplot(scaled_df['Last_performance_score_Training_score_average_mean'], ax=ax2)\n",
    "# sns.kdeplot(scaled_df['Division_Training_score_average_mean'], ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain[num_attributes] = xtrain_s\n",
    "xtest[num_attributes] = xtest_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(xtrain)\n",
    "xtrain = scaler.transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA to remove the redundant features from the datasets without losing much information. As we have noticed high corrolations in the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlim(0,85,1)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the first 20 components\n",
    "from sklearn.decomposition import PCA \n",
    "sklearn_pca = PCA(n_components=60)\n",
    "final_pca = sklearn_pca.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = sklearn_pca.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = final_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sm = SMOTE(random_state=42,ratio={1:3000})\n",
    "X_res, y_res = sm.fit_sample(xtrain, ytrain)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=200, max_depth=4, min_child_weight=5,nthread=4, subsample=0.8, colsample_bytree=0.8,\n",
    "                           objective = 'binary:logistic')\n",
    "\n",
    "# Create parameter grid\n",
    "parameters = {\n",
    "              \"learning_rate\": [0.1, 0.2],}\n",
    "               #\"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2]}\n",
    "              # \"max_depth\": [2, 4, 7, 10],\n",
    "              # \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "            #   \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "             #  \"reg_alpha\": [0, 0.5, 1],\n",
    "             #  \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "             #  \"min_child_weight\": [1, 3, 5, 7],\n",
    "             #  \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create RandomizedSearchCV Object\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = parameters, scoring = \"f1\",\n",
    "                             cv = 1, verbose = 3, random_state = 40 )\n",
    "\n",
    "# Fit the model\n",
    "model_xgboost = xgb_rscv.fit(xtrain, ytrain)\n",
    "\n",
    "# Model best estimators\n",
    "print(\"Learning Rate: \", model_xgboost.best_estimator_.get_params()[\"learning_rate\"])\n",
    "print(\"Gamma: \", model_xgboost.best_estimator_.get_params()[\"gamma\"])\n",
    "print(\"Max Depth: \", model_xgboost.best_estimator_.get_params()[\"max_depth\"])\n",
    "print(\"Subsample: \", model_xgboost.best_estimator_.get_params()[\"subsample\"])\n",
    "print(\"Max Features at Split: \", model_xgboost.best_estimator_.get_params()[\"colsample_bytree\"])\n",
    "print(\"Alpha: \", model_xgboost.best_estimator_.get_params()[\"reg_alpha\"])\n",
    "print(\"Lamda: \", model_xgboost.best_estimator_.get_params()[\"reg_lambda\"])\n",
    "print(\"Minimum Sum of the Instance Weight Hessian to Make a Child: \",\n",
    "      model_xgboost.best_estimator_.get_params()[\"min_child_weight\"])\n",
    "print(\"Number of Trees: \", model_xgboost.best_estimator_.get_params()[\"n_estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"spw: \", model_xgboost.best_estimator_.get_params()[\"scale_pos_weight\"])\n",
    "print(\"base score: \", model_xgboost.best_estimator_.get_params()[\"base_score\"])\n",
    "print(\"max_delta_step: \", model_xgboost.best_estimator_.get_params()[\"max_delta_step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 of kfold5\n",
      "model\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.4,\n",
      "              learning_rate=0.1, max_delta_step=2, max_depth=4,\n",
      "              min_child_weight=5, missing=None, n_estimators=200, n_jobs=1,\n",
      "              nthread=4, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=2, seed=29,\n",
      "              silent=None, subsample=0.8, verbosity=1)\n",
      "confusion matrix\n",
      "[[5560   52]\n",
      " [ 307  212]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5612\n",
      "           1       0.80      0.41      0.54       519\n",
      "\n",
      "    accuracy                           0.94      6131\n",
      "   macro avg       0.88      0.70      0.76      6131\n",
      "weighted avg       0.94      0.94      0.93      6131\n",
      "\n",
      "Accuracy : 0.941445\n",
      "f1 score : 0.541507\n",
      "\n",
      "2 of kfold5\n",
      "model\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.4,\n",
      "              learning_rate=0.1, max_delta_step=2, max_depth=4,\n",
      "              min_child_weight=5, missing=None, n_estimators=200, n_jobs=1,\n",
      "              nthread=4, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=2, seed=29,\n",
      "              silent=None, subsample=0.8, verbosity=1)\n",
      "confusion matrix\n",
      "[[5572   39]\n",
      " [ 345  174]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      5611\n",
      "           1       0.82      0.34      0.48       519\n",
      "\n",
      "    accuracy                           0.94      6130\n",
      "   macro avg       0.88      0.66      0.72      6130\n",
      "weighted avg       0.93      0.94      0.93      6130\n",
      "\n",
      "Accuracy : 0.937357\n",
      "f1 score : 0.475410\n",
      "\n",
      "3 of kfold5\n",
      "model\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.4,\n",
      "              learning_rate=0.1, max_delta_step=2, max_depth=4,\n",
      "              min_child_weight=5, missing=None, n_estimators=200, n_jobs=1,\n",
      "              nthread=4, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=2, seed=29,\n",
      "              silent=None, subsample=0.8, verbosity=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-eeeee20cb272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelXg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mypredrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelXg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'confusion matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myvl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypredrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1290\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[1;32m   1293\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 1 \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn import metrics\n",
    "kf = StratifiedKFold(n_splits=5, random_state=42,shuffle=True)\n",
    "xtrain = np.array(xtrain_poly)\n",
    "ytrain =  np.array(ytrain)\n",
    "for train_index,test_index in kf.split(xtrain,ytrain):\n",
    "    print('\\n{} of kfold{}'.format(i, kf.n_splits))\n",
    "    xtr,xvl = xtrain[train_index], xtrain[test_index]\n",
    "    ytr,yvl = ytrain[train_index], ytrain[test_index]\n",
    "  #  modelXg = LogisticRegression(C=1, penalty=\"l1\")\n",
    "    from xgboost import XGBClassifier\n",
    "    modelXg = XGBClassifier( learning_rate=0.1, n_estimators=200, max_depth=4, min_child_weight=5, \n",
    "                      gamma=0.4,nthread=4, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',scale_pos_weight=2,\n",
    "                            max_delta_step =2, seed=29,)\n",
    "    modelXg.fit(xtr, ytr)\n",
    "    print('model')\n",
    "    print(modelXg)\n",
    "\n",
    "    ypredrf = modelXg.predict(xvl)\n",
    "    print('confusion matrix')\n",
    "    print(metrics.confusion_matrix(yvl, ypredrf))\n",
    "    print('classification report')\n",
    "    print(metrics.classification_report(yvl, ypredrf))\n",
    "    print('Accuracy : %f' % (metrics.accuracy_score(yvl, ypredrf)))\n",
    "    print('f1 score : %f' % (metrics.f1_score(yvl, ypredrf)))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "feat = xtrain[num_attributes]\n",
    "scaler = MinMaxScaler().fit(feat.values)\n",
    "xtrain_s = scaler.transform(feat.values)\n",
    "xtest_s = scaler.transform(xtest[num_attributes].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(xtrain)\n",
    "xtrain = scaler.transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain[num_attributes] = xtrain_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[num_attributes] = xtest_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.2, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=190,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "confusion matrix\n",
      "[[6998   17]\n",
      " [ 426  222]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7015\n",
      "           1       0.93      0.34      0.50       648\n",
      "\n",
      "    accuracy                           0.94      7663\n",
      "   macro avg       0.94      0.67      0.73      7663\n",
      "weighted avg       0.94      0.94      0.93      7663\n",
      "\n",
      "Accuracy : 0.942190\n",
      "f1 score : 0.500564\n",
      "f1 score : 0.531992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "#rfmodel =DecisionTreeClassifier()\n",
    "#rfmodel = KNeighborsClassifier(n_neighbors=10)\n",
    "#rfmodel = LogisticRegression(C=1, penalty=\"l1\")\n",
    "#cat_model = KNeighborsClassifier(n_neighbors=3)\n",
    "rfmodel= GradientBoostingClassifier(learning_rate=0.2, n_estimators=190)\n",
    "#rfmodel = RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.6000000000000001, min_samples_leaf=4, min_samples_split=4, n_estimators=100)\n",
    "#rfmodel = cb.CatBoostClassifier(iterations=1000, use_best_model=True, eval_metric='F1', random_seed=45)#rfmodel = GradientBoostingClassifier(n_estimators= 150)\n",
    "rfmodel.fit(xtrain,ytrain)#, eval_set=(xtest, ytest))\n",
    "print('model')\n",
    "print(rfmodel)\n",
    "\n",
    "ypredrf = rfmodel.predict(xtest)\n",
    "ypredtrain = rfmodel.predict(xtrain)\n",
    "\n",
    "print('confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, ypredrf))\n",
    "\n",
    "print('classification report')\n",
    "print(metrics.classification_report(ytest, ypredrf))\n",
    "print('Accuracy : %f' % (metrics.accuracy_score(ytest, ypredrf)))\n",
    "print('f1 score : %f' % (metrics.f1_score(ytest, ypredrf)))\n",
    "print('f1 score : %f' % (metrics.f1_score(ytrain, ypredtrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "eval_set = [(xtest, ytest)]\n",
    "modelXg = XGBClassifier(learning_rate=0.1, n_estimators=200, max_depth=4, min_child_weight=5,\n",
    "                      gamma=0.4,nthread=4, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',scale_pos_weight=3,seed=29,\n",
    "                       )\n",
    "modelXg.fit(xtrain, ytrain)\n",
    "y_xgb=modelXg.predict(xtest)\n",
    "ypredtrain = modelXg.predict(xtrain)\n",
    "prediction=rfmodel.predict(test_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(ytest,y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'EmployeeNo':test_data['EmployeeNo'],'Promoted_or_Not':prediction})#.Promoted_or_Not.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissionDSN4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "eval_set = [(xtest, ytest)]\n",
    "\n",
    "#Set eval_metrics as logloss, early_stopping_round as 5 \n",
    "xgb.fit(xtrain, ytrain, early_stopping_rounds=5, eval_metric=\"logloss\", eval_set=eval_set, verbose=True,) \n",
    "# make predictions for test data \n",
    "y_xgb=xgb.predict(xtest)\n",
    "\n",
    "# evaluate predictions\n",
    "print(metrics.classification_report(ytest,y_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine whether your model is overfitting or not , with the help of ROC.\n",
    "print(confusion_matrix(ytest, y_xgb))\n",
    "predictions = [value for value in y_xgb]\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "precision = precision_score(ytest, predictions)\n",
    "recall = recall_score(ytest, predictions)\n",
    "f1 = f1_score(ytest, predictions)\n",
    "print(\"Accuracy_score: %.2f%% on test dataset\" % (accuracy * 100.0))\n",
    "print(\"precision_score: %.2f%% on test dataset\" % (precision * 100.0))\n",
    "print(\"recall_score: %.2f%% on test dataset\" % (recall * 100.0))\n",
    "print(\"f1_score: %.2f%% on test dataset\" % (f1 * 100.0))\n",
    "print('f1 score : %.2f%%' % (f1_score(ytrain, ypredtrain)* 100.0))\n",
    "print(\"roc_auc test set\", roc_auc_score(ytest, modelXg.predict_proba(xtest)[:,1]))\n",
    "print(\"roc_auc training set\", roc_auc_score(ytrain, modelXg.predict_proba(xtrain)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats = modelXg.feature_importances_\n",
    "imp_cols = new_data.columns\n",
    "feats_imp = pd.DataFrame({\"features\": imp_cols, \"importance\": imp_feats}).sort_values(by='importance', ascending=False)\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(x='features', y='importance', data=feats_imp)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature importance plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
